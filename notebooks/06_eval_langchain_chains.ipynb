{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsXAs2gcIpbC"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZX50cNFOFBt"
   },
   "source": [
    " # Evaluate LangChain | Gen AI Evaluation SDK Tutorial\n",
    "\n",
    " <table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/evaluate_langchain_chains.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fevaluation%2Fevaluate_langchain_chains.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/evaluation/evaluate_langchain_chains.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/evaluate_langchain_chains.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usd0d_LiOFBt"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Elia Secchi](https://github.com/eliasecchig) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vertex AI Evaluation enables evaluation of any callable Python function:** \n",
    "\n",
    "* RAG or Agents systems developed using `Langchain` or `LLamaIndex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjDmmmDaOFBt"
   },
   "source": [
    "## Overview\n",
    "\n",
    "With this tutorial, you learn how to evaluate the performance of a conversational LangChain chain using the *Vertex AI Python SDK for Gen AI Evaluation Service*. The notebook utilizes a dummy chatbot designed to provide recipe suggestions.\n",
    "\n",
    "The tutorial goes trough:\n",
    "1. Data preparation\n",
    "2. Setting up the LangChain chain\n",
    "3. Set-up a custom metric\n",
    "4. Run evaluation with a combination of custom metrics and built-in metrics.\n",
    "5. Log results into an experiment run and analyze different runs.\n",
    "\n",
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-OcPSC8_FUX"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7Jso8-FO4N8"
   },
   "source": [
    "### Install Vertex AI SDK for Rapid Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUat7NRq5JDC"
   },
   "outputs": [],
   "source": [
    "# %pip install --quiet --upgrade nest_asyncio\n",
    "# %pip install --upgrade --user --quiet langchain-core langchain-google-vertexai langchain\n",
    "# %pip install --upgrade --user --quiet \"google-cloud-aiplatform[evaluation]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### tmp - debugging START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter/jtott/diy-rag/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tmp - debugging END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>‚ö†Ô∏è The kernel is going to restart. Wait until it's finished before continuing to the next step. ‚ö†Ô∏è</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"hybrid-vertex\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvhI92xhQTzk"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qP4ihOCkEBje",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "import json\n",
    "import logging\n",
    "from typing import Any\n",
    "import warnings\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "# Main\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import vertexai\n",
    "from vertexai.evaluation import CustomMetric, EvalTask\n",
    "\n",
    "# General\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDmLyf-K5nRz"
   },
   "source": [
    "### Library settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KRkatYS95mLP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l26gX-cHOFBu"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gT_OJBHfCg4Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_multiturn_history(df: pd.DataFrame):\n",
    "    \"\"\"Processes a DataFrame of messages to add conversation history for each message.\n",
    "\n",
    "    This function takes a DataFrame containing message data and iterates through each row.\n",
    "    For each message in a row, it constructs the conversation history up to that point by\n",
    "    accumulating previous user and AI messages. This conversation history is then added\n",
    "    to the message data, and the processed messages are returned as a new DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: A DataFrame containing message data. It is expected to have a column named\n",
    "            \"messages\" where each entry is a list of dictionaries representing messages in\n",
    "            a conversation. Each message dictionary should have \"user\" and \"reference\" keys.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with the processed messages. Each message dictionary will now have an\n",
    "        additional \"conversation_history\" key containing a list of tuples representing the\n",
    "        conversation history leading up to that message. The tuples are of the form\n",
    "        (\"user\", message_text) or (\"ai\", message_text).\n",
    "    \"\"\"\n",
    "    processed_messages = []\n",
    "    for i, row in df.iterrows():\n",
    "        conversation_history = []\n",
    "        for message in row[\"messages\"]:\n",
    "            message[\"conversation_history\"] = conversation_history\n",
    "            processed_messages.append(message)\n",
    "            conversation_history = conversation_history + [\n",
    "                (\"user\", message[\"user\"]),\n",
    "                (\"ai\", message[\"reference\"]),\n",
    "            ]\n",
    "    return pd.DataFrame(processed_messages)\n",
    "\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"\"\"Creates an iterable with tuples paired together\n",
    "    e.g s -> (s0, s1), (s2, s3), (s4, s5), ...\n",
    "    \"\"\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "\n",
    "def batch_generate_message(row: dict, callable: Any) -> dict:\n",
    "    \"\"\"\n",
    "    Predicts a response from a chat agent.\n",
    "\n",
    "    Args:\n",
    "        callable (ChatAgent): A chat agent.\n",
    "        row (dict): A message.\n",
    "    Returns:\n",
    "        dict: The predicted response.\n",
    "    \"\"\"\n",
    "    index, message = row\n",
    "\n",
    "    messages = []\n",
    "    for user_message, ground_truth in pairwise(message.get(\"conversation_history\", [])):\n",
    "        messages.append((\"user\", user_message))\n",
    "        messages.append((\"ai\", ground_truth))\n",
    "    messages.append((\"user\", message[\"user\"]))\n",
    "    input_callable = {\"messages\": messages, **message.get(\"callable_kwargs\", {})}\n",
    "    response = callable.invoke(input_callable)\n",
    "    message[\"response\"] = response.content\n",
    "    message[\"response_obj\"] = response\n",
    "    return message\n",
    "\n",
    "\n",
    "def batch_generate_messages(\n",
    "    messages: pd.DataFrame, callable: Any, max_workers: int = 4\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates AI-powered responses to a series of user messages using a provided callable.\n",
    "\n",
    "    This function efficiently processes a Pandas DataFrame containing user-AI message pairs,\n",
    "     utilizing the specified callable (either a LangChain Chain or a custom class with an\n",
    "     `invoke` method) to predict AI responses in parallel.\n",
    "\n",
    "    Args:\n",
    "        callable (callable): A callable object (e.g., LangChain Chain, custom class) used\n",
    "            for response generation. Must have an `invoke(messages: dict) ->\n",
    "            langchain_core.messages.ai.AIMessage` method.\n",
    "            The `messages` dict follows this structure:\n",
    "            {\"messages\" [(\"user\", \"first\"),(\"ai\", \"a response\"), (\"user\", \"a follow up\")]}\n",
    "\n",
    "        messages (pd.DataFrame): A DataFrame with one column named 'messages' containing\n",
    "            the list of user-AI message pairs as described above.\n",
    "\n",
    "        max_workers (int, optional): The number of worker processes to use for parallel\n",
    "            prediction. Defaults to the number of available CPU cores.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the original messages and a new column with the predicted AI responses.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        messages_df = pd.DataFrame({\n",
    "            \"messages\": [\n",
    "                [{\"user\": \"What's the weather today?\", \"reference\": \"It's sunny.\"}],\n",
    "                [{\"user\": \"Tell me a joke.\", \"reference\": \"Why did the scarecrow win an award?...\n",
    "                    Because he was outstanding in his field!\"}]\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        responses_df = batch_generate_messages(my_callable, messages_df)\n",
    "        ```\n",
    "    \"\"\"\n",
    "    logging.info(\"Executing batch scoring\")\n",
    "    predicted_messages = []\n",
    "    with ThreadPoolExecutor(max_workers) as pool:\n",
    "        partial_func = partial(batch_generate_message, callable=callable)\n",
    "        for message in tqdm(\n",
    "            pool.map(partial_func, messages.iterrows()), total=len(messages)\n",
    "        ):\n",
    "            predicted_messages.append(message)\n",
    "    return pd.DataFrame(predicted_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZMXiJhKD2TY"
   },
   "source": [
    "## Import ground truth data for evaluation\n",
    "\n",
    "In this sample, we will use 2 conversations as a ground truth. Every message in the conversations, along with the relative history, will be used to produce a response with a foundational model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT = \"eval-chains\"\n",
    "LOCAL_DIR = f\"files/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(LOCAL_DIR):\n",
    "    os.makedirs(LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files/eval-chains'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write messages to yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jwqlusT7OJ4J",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing files/eval-chains/chats.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {LOCAL_DIR}/chats.yaml\n",
    "- messages:\n",
    "  - user: Hi\n",
    "    reference: Hi, how can I help you?\n",
    "  - user: I'm looking for a recipe for a healthy dinner. Do you have any recommendations?\n",
    "    reference: Sure, I can help you with that. What are your dietary restrictions? Are you vegetarian, vegan, gluten-free, or anything else?\n",
    "  - user: I'm not vegetarian or vegan, but I am gluten-free.\n",
    "    reference: 'Okay, I ll keep that in mind. Here are a few recipes that I think you might like:\n",
    "  * **Grilled Salmon with Roasted Vegetables:** This is a delicious and healthy recipe that is perfect for a weeknight meal. The salmon is grilled to perfection and the roasted vegetables add a touch of sweetness.\n",
    "  * **Chicken Stir-Fry:** This is a quick and easy stir-fry that is perfect for busy weeknights. The chicken is cooked with vegetables and a light sauce.\n",
    "  * **Lentil Soup:** This is a hearty and healthy soup that is perfect for a cold winter day. The lentils are packed with protein and fiber, and the soup is also gluten-free.'\n",
    "  - user: Those all sound great! I think I'm going to try the grilled salmon with roasted vegetables.\n",
    "    reference: That's a great choice! I hope you enjoy it.\n",
    "  - user: Thanks for your help!\n",
    "    reference: You're welcome! Is there anything else I can help you with today?\n",
    "  - user: No, that's all. Thanks again!\n",
    "    reference: You're welcome! Have a great day!\n",
    "- messages:\n",
    "  - user: Hi\n",
    "    reference: Hi, how can I help you?\n",
    "  - user: I'm looking for a recipe for a romantic dinner. Do you have any recommendations?\n",
    "    reference: Sure, I can help you with that. What are your dietary restrictions? Are you vegetarian, vegan, gluten-free, or anything else?\n",
    "  - user: I'm vegetarian.\n",
    "    reference: 'Sure, I can help you find a healthy vegetarian dinner recipe. Here are a few ideas:\n",
    "    * **Burnt aubergine veggie chilli:** This is a hearty and flavorful dish that is packed with nutrients. The roasted aubergine gives it a smoky flavor, and the lentils and beans add protein and fiber.\n",
    "  * **Simple mushroom curry:** This is a quick and easy curry that is perfect for a weeknight meal. The mushrooms are cooked in a creamy sauce with spices, and the whole dish is ready in under 30 minutes.\n",
    "  * **Vegetarian enchiladas:** This is a classic Mexican dish that is easy to make vegetarian. The enchiladas are filled with a variety of vegetables, and they are topped with a delicious sauce.\n",
    "  * **Braised sesame tofu:** This is a flavorful and satisfying dish that is perfect for a cold night. The tofu is braised in a sauce with sesame, ginger, and garlic, and it is served over rice or noodles.\n",
    "  * **Roast garlic & tahini spinach:** This is a light and healthy dish that is perfect for a spring or summer meal. The spinach is roasted with garlic and tahini, and it is served with a side of pita bread.\n",
    "\n",
    "  These are just a few ideas to get you started. There are many other great vegetarian dinner recipes out there, so you are sure to find something that you will enjoy.'\n",
    "  - user: Those all sound great! I like the Burnt aubergine veggie chilli\n",
    "    reference: That's a great choice! I hope you enjoy it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie7KTd_OjwdE"
   },
   "source": [
    "Let's now load all the messages into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "j0eSy_avGCW7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'user': 'Hi', 'reference': 'Hi, how can I he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'user': 'Hi', 'reference': 'Hi, how can I he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages\n",
       "0  [{'user': 'Hi', 'reference': 'Hi, how can I he...\n",
       "1  [{'user': 'Hi', 'reference': 'Hi, how can I he..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = yaml.safe_load(open(f\"{LOCAL_DIR}/chats.yaml\"))\n",
    "df = pd.DataFrame(y)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA7G0bDTj84z"
   },
   "source": [
    "**Decomposing the chat message input/output pairs**\n",
    "\n",
    "We are now ready for decomposing multi-turn history. This is essential to enable batch prediction.\n",
    "\n",
    "We decompose the `messages` list into single input/output pairs. The input is always composed by `user message`, `reference message` and `conversation_history`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Example:**\n",
    "\n",
    "Given the following chat:\n",
    "\n",
    "```yaml\n",
    "- messages:\n",
    "- user: Hi\n",
    "reference: Hi, how can I help you?\n",
    "- user: I'm looking for a recipe for a healthy dinner. Do you have any recommendations?\n",
    "reference: Sure, I can help you with that. What are your dietary restrictions? Are you vegetarian, vegan, gluten-free, or anything else?\n",
    "```\n",
    "\n",
    "We can generate these two input/output samples:\n",
    "\n",
    "```yaml\n",
    "- user: Hi\n",
    "  reference: Hi, how can I help you?\n",
    "  conversation_history: []\n",
    "\n",
    "- user: I'm looking for a recipe for a healthy dinner....\n",
    "  reference: Sure, I can help you with that. What are your ...\n",
    "  conversation_history:\n",
    "  - user: Hi\n",
    "    reference: Hi, how can I help you?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1FL0R3YXPj3e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>reference</th>\n",
       "      <th>conversation_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi, how can I help you?</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking for a recipe for a healthy dinner....</td>\n",
       "      <td>Sure, I can help you with that. What are your ...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not vegetarian or vegan, but I am gluten-f...</td>\n",
       "      <td>Okay, I ll keep that in mind. Here are a few r...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Those all sound great! I think I'm going to tr...</td>\n",
       "      <td>That's a great choice! I hope you enjoy it.</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for your help!</td>\n",
       "      <td>You're welcome! Is there anything else I can h...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No, that's all. Thanks again!</td>\n",
       "      <td>You're welcome! Have a great day!</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi, how can I help you?</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm looking for a recipe for a romantic dinner...</td>\n",
       "      <td>Sure, I can help you with that. What are your ...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm vegetarian.</td>\n",
       "      <td>Sure, I can help you find a healthy vegetarian...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Those all sound great! I like the Burnt auberg...</td>\n",
       "      <td>That's a great choice! I hope you enjoy it.</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0                                                 Hi   \n",
       "1  I'm looking for a recipe for a healthy dinner....   \n",
       "2  I'm not vegetarian or vegan, but I am gluten-f...   \n",
       "3  Those all sound great! I think I'm going to tr...   \n",
       "4                              Thanks for your help!   \n",
       "5                      No, that's all. Thanks again!   \n",
       "6                                                 Hi   \n",
       "7  I'm looking for a recipe for a romantic dinner...   \n",
       "8                                    I'm vegetarian.   \n",
       "9  Those all sound great! I like the Burnt auberg...   \n",
       "\n",
       "                                           reference  \\\n",
       "0                            Hi, how can I help you?   \n",
       "1  Sure, I can help you with that. What are your ...   \n",
       "2  Okay, I ll keep that in mind. Here are a few r...   \n",
       "3        That's a great choice! I hope you enjoy it.   \n",
       "4  You're welcome! Is there anything else I can h...   \n",
       "5                  You're welcome! Have a great day!   \n",
       "6                            Hi, how can I help you?   \n",
       "7  Sure, I can help you with that. What are your ...   \n",
       "8  Sure, I can help you find a healthy vegetarian...   \n",
       "9        That's a great choice! I hope you enjoy it.   \n",
       "\n",
       "                                conversation_history  \n",
       "0                                                 []  \n",
       "1        [(user, Hi), (ai, Hi, how can I help you?)]  \n",
       "2  [(user, Hi), (ai, Hi, how can I help you?), (u...  \n",
       "3  [(user, Hi), (ai, Hi, how can I help you?), (u...  \n",
       "4  [(user, Hi), (ai, Hi, how can I help you?), (u...  \n",
       "5  [(user, Hi), (ai, Hi, how can I help you?), (u...  \n",
       "6                                                 []  \n",
       "7        [(user, Hi), (ai, Hi, how can I help you?)]  \n",
       "8  [(user, Hi), (ai, Hi, how can I help you?), (u...  \n",
       "9  [(user, Hi), (ai, Hi, how can I help you?), (u...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed = generate_multiturn_history(df)\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OhQLR1lGsEq"
   },
   "source": [
    "## Let's define our LangChain chain!\n",
    "\n",
    "We now need to define our LangChain Chain. For this tutorial, we will create a simple conversational chain capable of producing cooking recipes for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "u5B0ufczjfA_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(model_name=\"gemini-1.5-flash-001\", temperature=0)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a conversational bot that produce nice recipes for users based on a question.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MS9rlK6eq5qY"
   },
   "source": [
    "We can test our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qzMotN92qrqv",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! üëã  What kind of recipe are you looking for today?  Tell me about your cravings, dietary needs, or any ingredients you have on hand. I'm ready to whip up some culinary magic! ‚ú® \\n\", additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_LOW'}], 'usage_metadata': {'prompt_token_count': 19, 'candidates_token_count': 46, 'total_token_count': 65, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.13736608754033627, 'logprobs_result': {'top_candidates': [], 'chosen_candidates': []}}, id='run-f04c8f22-62ea-4130-a5ae-51f5450e6138-0', usage_metadata={'input_tokens': 19, 'output_tokens': 46, 'total_tokens': 65})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke([(\"human\", \"Hi there!\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqdVpTMkq_pc"
   },
   "source": [
    "## Batch scoring\n",
    "\n",
    "We are now ready to perform batch scoring. To perform batch scoring we will leverage the utility function `batch_generate_messages`\n",
    "\n",
    "Have a look at the definition to see the expected input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Qc4DiVYOKk6H",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function batch_generate_messages in module __main__:\n",
      "\n",
      "batch_generate_messages(messages: pandas.core.frame.DataFrame, callable: Any, max_workers: int = 4) -> pandas.core.frame.DataFrame\n",
      "    Generates AI-powered responses to a series of user messages using a provided callable.\n",
      "    \n",
      "    This function efficiently processes a Pandas DataFrame containing user-AI message pairs,\n",
      "     utilizing the specified callable (either a LangChain Chain or a custom class with an\n",
      "     `invoke` method) to predict AI responses in parallel.\n",
      "    \n",
      "    Args:\n",
      "        callable (callable): A callable object (e.g., LangChain Chain, custom class) used\n",
      "            for response generation. Must have an `invoke(messages: dict) ->\n",
      "            langchain_core.messages.ai.AIMessage` method.\n",
      "            The `messages` dict follows this structure:\n",
      "            {\"messages\" [(\"user\", \"first\"),(\"ai\", \"a response\"), (\"user\", \"a follow up\")]}\n",
      "    \n",
      "        messages (pd.DataFrame): A DataFrame with one column named 'messages' containing\n",
      "            the list of user-AI message pairs as described above.\n",
      "    \n",
      "        max_workers (int, optional): The number of worker processes to use for parallel\n",
      "            prediction. Defaults to the number of available CPU cores.\n",
      "    \n",
      "    Returns:\n",
      "        pd.DataFrame: A DataFrame containing the original messages and a new column with the predicted AI responses.\n",
      "    \n",
      "    Example:\n",
      "        ```python\n",
      "        messages_df = pd.DataFrame({\n",
      "            \"messages\": [\n",
      "                [{\"user\": \"What's the weather today?\", \"reference\": \"It's sunny.\"}],\n",
      "                [{\"user\": \"Tell me a joke.\", \"reference\": \"Why did the scarecrow win an award?...\n",
      "                    Because he was outstanding in his field!\"}]\n",
      "            ]\n",
      "        })\n",
      "    \n",
      "        responses_df = batch_generate_messages(my_callable, messages_df)\n",
      "        ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(batch_generate_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Pip0WjopXMsu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  4.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>reference</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>response</th>\n",
       "      <th>response_obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi, how can I help you?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hi there! üëã  What kind of recipe are you looki...</td>\n",
       "      <td>content=\"Hi there! üëã  What kind of recipe are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking for a recipe for a healthy dinner....</td>\n",
       "      <td>Sure, I can help you with that. What are your ...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?)]</td>\n",
       "      <td>I'd love to help! To give you the best recomme...</td>\n",
       "      <td>content=\"I'd love to help! To give you the bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not vegetarian or vegan, but I am gluten-f...</td>\n",
       "      <td>Okay, I ll keep that in mind. Here are a few r...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>Okay, great! How about a delicious and healthy...</td>\n",
       "      <td>content=\"Okay, great! How about a delicious an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Those all sound great! I think I'm going to tr...</td>\n",
       "      <td>That's a great choice! I hope you enjoy it.</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>aiThat's a great choice! It's a delicious and ...</td>\n",
       "      <td>content=\"aiThat's a great choice! It's a delic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for your help!</td>\n",
       "      <td>You're welcome! Is there anything else I can h...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>You're welcome! Let me know if you need any mo...</td>\n",
       "      <td>content=\"You're welcome! Let me know if you ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No, that's all. Thanks again!</td>\n",
       "      <td>You're welcome! Have a great day!</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>You're very welcome! Have a great day! üòä \\n</td>\n",
       "      <td>content=\"You're very welcome! Have a great day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi, how can I help you?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hi there! üëã  What kind of recipe are you looki...</td>\n",
       "      <td>content=\"Hi there! üëã  What kind of recipe are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm looking for a recipe for a romantic dinner...</td>\n",
       "      <td>Sure, I can help you with that. What are your ...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?)]</td>\n",
       "      <td>Of course! To give you the best recommendation...</td>\n",
       "      <td>content=\"Of course! To give you the best recom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm vegetarian.</td>\n",
       "      <td>Sure, I can help you find a healthy vegetarian...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>Okay, here's a romantic vegetarian dinner reci...</td>\n",
       "      <td>content=\"Okay, here's a romantic vegetarian di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Those all sound great! I like the Burnt auberg...</td>\n",
       "      <td>That's a great choice! I hope you enjoy it.</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>aiThat's a great choice! It's a hearty and fla...</td>\n",
       "      <td>content=\"aiThat's a great choice! It's a heart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0                                                 Hi   \n",
       "1  I'm looking for a recipe for a healthy dinner....   \n",
       "2  I'm not vegetarian or vegan, but I am gluten-f...   \n",
       "3  Those all sound great! I think I'm going to tr...   \n",
       "4                              Thanks for your help!   \n",
       "5                      No, that's all. Thanks again!   \n",
       "6                                                 Hi   \n",
       "7  I'm looking for a recipe for a romantic dinner...   \n",
       "8                                    I'm vegetarian.   \n",
       "9  Those all sound great! I like the Burnt auberg...   \n",
       "\n",
       "                                           reference  \\\n",
       "0                            Hi, how can I help you?   \n",
       "1  Sure, I can help you with that. What are your ...   \n",
       "2  Okay, I ll keep that in mind. Here are a few r...   \n",
       "3        That's a great choice! I hope you enjoy it.   \n",
       "4  You're welcome! Is there anything else I can h...   \n",
       "5                  You're welcome! Have a great day!   \n",
       "6                            Hi, how can I help you?   \n",
       "7  Sure, I can help you with that. What are your ...   \n",
       "8  Sure, I can help you find a healthy vegetarian...   \n",
       "9        That's a great choice! I hope you enjoy it.   \n",
       "\n",
       "                                conversation_history  \\\n",
       "0                                                 []   \n",
       "1        [(user, Hi), (ai, Hi, how can I help you?)]   \n",
       "2  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "3  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "4  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "5  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "6                                                 []   \n",
       "7        [(user, Hi), (ai, Hi, how can I help you?)]   \n",
       "8  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "9  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Hi there! üëã  What kind of recipe are you looki...   \n",
       "1  I'd love to help! To give you the best recomme...   \n",
       "2  Okay, great! How about a delicious and healthy...   \n",
       "3  aiThat's a great choice! It's a delicious and ...   \n",
       "4  You're welcome! Let me know if you need any mo...   \n",
       "5        You're very welcome! Have a great day! üòä \\n   \n",
       "6  Hi there! üëã  What kind of recipe are you looki...   \n",
       "7  Of course! To give you the best recommendation...   \n",
       "8  Okay, here's a romantic vegetarian dinner reci...   \n",
       "9  aiThat's a great choice! It's a hearty and fla...   \n",
       "\n",
       "                                        response_obj  \n",
       "0  content=\"Hi there! üëã  What kind of recipe are ...  \n",
       "1  content=\"I'd love to help! To give you the bes...  \n",
       "2  content=\"Okay, great! How about a delicious an...  \n",
       "3  content=\"aiThat's a great choice! It's a delic...  \n",
       "4  content=\"You're welcome! Let me know if you ne...  \n",
       "5  content=\"You're very welcome! Have a great day...  \n",
       "6  content=\"Hi there! üëã  What kind of recipe are ...  \n",
       "7  content=\"Of course! To give you the best recom...  \n",
       "8  content=\"Okay, here's a romantic vegetarian di...  \n",
       "9  content=\"aiThat's a great choice! It's a heart...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_data = batch_generate_messages(messages=df_processed, callable=chain)\n",
    "scored_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Tf1bssiSBk7"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We'll utilize [Vertex AI Rapid Evaluation](https://cloud.google.com/vertex-ai/generative-ai/docs/models/rapid-evaluation) to assess our generative AI model's performance. This service within Vertex AI streamlines the evaluation process, integrates with [Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/intro-vertex-ai-experiments) for tracking, and offers a range of [pre-built metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#task-and-metrics) and the capability to define custom ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZSzjLI_rBSp"
   },
   "source": [
    "#### Define a CustomMetric using Gemini model\n",
    "\n",
    "Define a customized Gemini model-based metric function, with explanations for the score. The registered custom metrics are computed on the client side, without using online evaluation service APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aT0uclHrSBlC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator_llm = ChatVertexAI(\n",
    "    model_name=\"gemini-1.5-flash-001\",\n",
    "    temperature=0,\n",
    "    response_mime_type=\"application/json\",\n",
    ")\n",
    "\n",
    "\n",
    "def custom_faithfulness(instance):\n",
    "    prompt = f\"\"\"You are examining written text content. Here is the text:\n",
    "************\n",
    "Written content: {instance[\"response\"]}\n",
    "************\n",
    "Original source data: {instance[\"reference\"]}\n",
    "\n",
    "Examine the text and determine whether the text is faithful or not.\n",
    "Faithfulness refers to how accurately a generated summary reflects the essential information and key concepts present in the original source document.\n",
    "A faithful summary stays true to the facts and meaning of the source text, without introducing distortions, hallucinations, or information that wasn't originally there.\n",
    "\n",
    "Your response must be an explanation of your thinking along with single integer number on a scale of 0-5, 0\n",
    "the least faithful and 5 being the most faithful.\n",
    "\n",
    "Produce results in JSON\n",
    "\n",
    "Expected format:\n",
    "\n",
    "```json\n",
    "{{\n",
    "    \"explanation\": \"< your explanation>\",\n",
    "    \"custom_faithfulness\": <your score>\n",
    "}}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    result = evaluator_llm.invoke([(\"human\", prompt)])\n",
    "    result = json.loads(result.content)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Register Custom Metric\n",
    "custom_faithfulness_metric = CustomMetric(\n",
    "    name=\"custom_faithfulness\",\n",
    "    metric_function=custom_faithfulness,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpdRqYlLq53t"
   },
   "source": [
    "### Run Evaluation with CustomMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "w4iU_mIhoY93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"rapid-eval-langchain-eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3r3NiKNqn3u"
   },
   "source": [
    "We are now ready to run the evaluation. We will use different metrics, combining the custom metric we defined above with some pre-built metrics.\n",
    "\n",
    "Results of the evaluation will be automatically tagged into the experiment_name we defined.\n",
    "\n",
    "You can click `View Experiment`, to see the experiment in Google Cloud Console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*see `EvalTask` [src](https://github.com/googleapis/python-aiplatform/blob/main/vertexai/evaluation/eval_task.py#L55) code definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zeVra-g1rAFV",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-8199f905-7040-4dcd-bb3b-9abc6b341fcc\" href=\"#view-view-vertex-resource-8199f905-7040-4dcd-bb3b-9abc6b341fcc\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-8199f905-7040-4dcd-bb3b-9abc6b341fcc');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/rapid-eval-langchain-eval/runs?project=hybrid-vertex');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/rapid-eval-langchain-eval/runs?project=hybrid-vertex', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/rapid-eval-langchain-eval-91e7935e-3c72-45d7-a3fe-d357d9f48341 to Experiment: rapid-eval-langchain-eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/rapid-eval-langchain-eval-91e7935e-3c72-45d7-a3fe-d357d9f48341 to Experiment: rapid-eval-langchain-eval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-d1a81f20-7583-4429-925c-f51ad81605be\" href=\"#view-view-vertex-resource-d1a81f20-7583-4429-925c-f51ad81605be\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-d1a81f20-7583-4429-925c-f51ad81605be');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/rapid-eval-langchain-eval/runs/rapid-eval-langchain-eval-91e7935e-3c72-45d7-a3fe-d357d9f48341?project=hybrid-vertex');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/rapid-eval-langchain-eval/runs/rapid-eval-langchain-eval-91e7935e-3c72-45d7-a3fe-d357d9f48341?project=hybrid-vertex', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics with a total of 40 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 40 Vertex Gen AI Evaluation Service API requests.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:34<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 40 metric requests are successfully computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:vertexai.evaluation._evaluation:All 40 metric requests are successfully computed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Took:34.68010614695959 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.evaluation._evaluation:Evaluation Took:34.68010614695959 seconds\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"fluency\", \"coherence\", \"safety\", custom_faithfulness_metric]\n",
    "\n",
    "eval_task = EvalTask(\n",
    "    dataset=scored_data,\n",
    "    metrics=metrics,\n",
    "    experiment=experiment_name,\n",
    "    metric_column_mapping={\"prompt\": \"user\"},\n",
    ")\n",
    "eval_result = eval_task.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka3tZCL_uurD"
   },
   "source": [
    "Once an eval result is produced, we are able to display summary metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KheOvIvtiRlz",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_count': 10,\n",
       " 'fluency/mean': 4.9,\n",
       " 'fluency/std': 0.3162277660168379,\n",
       " 'coherence/mean': 3.5,\n",
       " 'coherence/std': 1.5811388300841898,\n",
       " 'safety/mean': 1.0,\n",
       " 'safety/std': 0.0,\n",
       " 'custom_faithfulness/mean': 1.5,\n",
       " 'custom_faithfulness/std': 1.5811388300841898}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.summary_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcALGGlwu0p_"
   },
   "source": [
    "We are also able to display a pandas dataframe containing a detailed summary of how our eval dataset performed and relative granular metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9zJ686YYiWJC",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>reference</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>response</th>\n",
       "      <th>response_obj</th>\n",
       "      <th>custom_faithfulness/score</th>\n",
       "      <th>custom_faithfulness/explanation</th>\n",
       "      <th>fluency/explanation</th>\n",
       "      <th>fluency/score</th>\n",
       "      <th>coherence/explanation</th>\n",
       "      <th>coherence/score</th>\n",
       "      <th>safety/explanation</th>\n",
       "      <th>safety/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi, how can I help you?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hi there! üëã  What kind of recipe are you looki...</td>\n",
       "      <td>content=\"Hi there! üëã  What kind of recipe are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The provided text is not faithful to the origi...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The prompt is a simple greeting, \"Hi.\"...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The response is safe. It contains a greeting a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking for a recipe for a healthy dinner....</td>\n",
       "      <td>Sure, I can help you with that. What are your ...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?)]</td>\n",
       "      <td>I'd love to help! To give you the best recomme...</td>\n",
       "      <td>content=\"I'd love to help! To give you the bes...</td>\n",
       "      <td>2</td>\n",
       "      <td>The text is not faithful to the original sourc...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose of the prompt is to reques...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The response asks clarifying questions to bett...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not vegetarian or vegan, but I am gluten-f...</td>\n",
       "      <td>Okay, I ll keep that in mind. Here are a few r...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>Okay, great! How about a delicious and healthy...</td>\n",
       "      <td>content=\"Okay, great! How about a delicious an...</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text is not faithful to the origi...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose of the response is to ackn...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The response is safe. It suggests a gluten-fre...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Those all sound great! I think I'm going to tr...</td>\n",
       "      <td>That's a great choice! I hope you enjoy it.</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>aiThat's a great choice! It's a delicious and ...</td>\n",
       "      <td>content=\"aiThat's a great choice! It's a delic...</td>\n",
       "      <td>1</td>\n",
       "      <td>The generated text is not faithful to the orig...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The AI's r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>STEP 1: The purpose of the AI response is to a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is safe. It does not contain any ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for your help!</td>\n",
       "      <td>You're welcome! Is there anything else I can h...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>You're welcome! Let me know if you need any mo...</td>\n",
       "      <td>content=\"You're welcome! Let me know if you ne...</td>\n",
       "      <td>3</td>\n",
       "      <td>The generated text is similar to the original ...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose is to respond to a \"thank ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is safe as it does not contain an...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No, that's all. Thanks again!</td>\n",
       "      <td>You're welcome! Have a great day!</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>You're very welcome! Have a great day! üòä \\n</td>\n",
       "      <td>content=\"You're very welcome! Have a great day...</td>\n",
       "      <td>5</td>\n",
       "      <td>The generated text is identical to the origina...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: Identify the purpose and audience:\\nTh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is safe, as it does not contain h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi, how can I help you?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hi there! üëã  What kind of recipe are you looki...</td>\n",
       "      <td>content=\"Hi there! üëã  What kind of recipe are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The provided text is not faithful to the origi...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response, while cheerful and engaging, lac...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The response is safe. It contains a greeting a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm looking for a recipe for a romantic dinner...</td>\n",
       "      <td>Sure, I can help you with that. What are your ...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?)]</td>\n",
       "      <td>Of course! To give you the best recommendation...</td>\n",
       "      <td>content=\"Of course! To give you the best recom...</td>\n",
       "      <td>2</td>\n",
       "      <td>The text is not faithful to the original sourc...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose of the prompt is to get a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response is safe. It asks clarifying quest...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm vegetarian.</td>\n",
       "      <td>Sure, I can help you find a healthy vegetarian...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>Okay, here's a romantic vegetarian dinner reci...</td>\n",
       "      <td>content=\"Okay, here's a romantic vegetarian di...</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text is not faithful to the origi...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose of the response is to prov...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The response is safe. It provides a vegetarian...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Those all sound great! I like the Burnt auberg...</td>\n",
       "      <td>That's a great choice! I hope you enjoy it.</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>aiThat's a great choice! It's a hearty and fla...</td>\n",
       "      <td>content=\"aiThat's a great choice! It's a heart...</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text is not faithful to the origi...</td>\n",
       "      <td>STEP 1: Assess grammar correctness: The respon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STEP 1: The purpose of the response is to prov...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The AI-generated response is safe. It provides...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0                                                 Hi   \n",
       "1  I'm looking for a recipe for a healthy dinner....   \n",
       "2  I'm not vegetarian or vegan, but I am gluten-f...   \n",
       "3  Those all sound great! I think I'm going to tr...   \n",
       "4                              Thanks for your help!   \n",
       "5                      No, that's all. Thanks again!   \n",
       "6                                                 Hi   \n",
       "7  I'm looking for a recipe for a romantic dinner...   \n",
       "8                                    I'm vegetarian.   \n",
       "9  Those all sound great! I like the Burnt auberg...   \n",
       "\n",
       "                                           reference  \\\n",
       "0                            Hi, how can I help you?   \n",
       "1  Sure, I can help you with that. What are your ...   \n",
       "2  Okay, I ll keep that in mind. Here are a few r...   \n",
       "3        That's a great choice! I hope you enjoy it.   \n",
       "4  You're welcome! Is there anything else I can h...   \n",
       "5                  You're welcome! Have a great day!   \n",
       "6                            Hi, how can I help you?   \n",
       "7  Sure, I can help you with that. What are your ...   \n",
       "8  Sure, I can help you find a healthy vegetarian...   \n",
       "9        That's a great choice! I hope you enjoy it.   \n",
       "\n",
       "                                conversation_history  \\\n",
       "0                                                 []   \n",
       "1        [(user, Hi), (ai, Hi, how can I help you?)]   \n",
       "2  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "3  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "4  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "5  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "6                                                 []   \n",
       "7        [(user, Hi), (ai, Hi, how can I help you?)]   \n",
       "8  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "9  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Hi there! üëã  What kind of recipe are you looki...   \n",
       "1  I'd love to help! To give you the best recomme...   \n",
       "2  Okay, great! How about a delicious and healthy...   \n",
       "3  aiThat's a great choice! It's a delicious and ...   \n",
       "4  You're welcome! Let me know if you need any mo...   \n",
       "5        You're very welcome! Have a great day! üòä \\n   \n",
       "6  Hi there! üëã  What kind of recipe are you looki...   \n",
       "7  Of course! To give you the best recommendation...   \n",
       "8  Okay, here's a romantic vegetarian dinner reci...   \n",
       "9  aiThat's a great choice! It's a hearty and fla...   \n",
       "\n",
       "                                        response_obj  \\\n",
       "0  content=\"Hi there! üëã  What kind of recipe are ...   \n",
       "1  content=\"I'd love to help! To give you the bes...   \n",
       "2  content=\"Okay, great! How about a delicious an...   \n",
       "3  content=\"aiThat's a great choice! It's a delic...   \n",
       "4  content=\"You're welcome! Let me know if you ne...   \n",
       "5  content=\"You're very welcome! Have a great day...   \n",
       "6  content=\"Hi there! üëã  What kind of recipe are ...   \n",
       "7  content=\"Of course! To give you the best recom...   \n",
       "8  content=\"Okay, here's a romantic vegetarian di...   \n",
       "9  content=\"aiThat's a great choice! It's a heart...   \n",
       "\n",
       "  custom_faithfulness/score  \\\n",
       "0                         1   \n",
       "1                         2   \n",
       "2                         0   \n",
       "3                         1   \n",
       "4                         3   \n",
       "5                         5   \n",
       "6                         1   \n",
       "7                         2   \n",
       "8                         0   \n",
       "9                         0   \n",
       "\n",
       "                     custom_faithfulness/explanation  \\\n",
       "0  The provided text is not faithful to the origi...   \n",
       "1  The text is not faithful to the original sourc...   \n",
       "2  The provided text is not faithful to the origi...   \n",
       "3  The generated text is not faithful to the orig...   \n",
       "4  The generated text is similar to the original ...   \n",
       "5  The generated text is identical to the origina...   \n",
       "6  The provided text is not faithful to the origi...   \n",
       "7  The text is not faithful to the original sourc...   \n",
       "8  The provided text is not faithful to the origi...   \n",
       "9  The provided text is not faithful to the origi...   \n",
       "\n",
       "                                 fluency/explanation  fluency/score  \\\n",
       "0  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "1  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "2  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "3  STEP 1: Assess grammar correctness: The AI's r...            4.0   \n",
       "4  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "5  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "6  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "7  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "8  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "9  STEP 1: Assess grammar correctness: The respon...            5.0   \n",
       "\n",
       "                               coherence/explanation  coherence/score  \\\n",
       "0  STEP 1: The prompt is a simple greeting, \"Hi.\"...              2.0   \n",
       "1  STEP 1: The purpose of the prompt is to reques...              2.0   \n",
       "2  STEP 1: The purpose of the response is to ackn...              4.0   \n",
       "3  STEP 1: The purpose of the AI response is to a...              5.0   \n",
       "4  STEP 1: The purpose is to respond to a \"thank ...              5.0   \n",
       "5  STEP 1: Identify the purpose and audience:\\nTh...              5.0   \n",
       "6  The response, while cheerful and engaging, lac...              2.0   \n",
       "7  STEP 1: The purpose of the prompt is to get a ...              1.0   \n",
       "8  STEP 1: The purpose of the response is to prov...              4.0   \n",
       "9  STEP 1: The purpose of the response is to prov...              5.0   \n",
       "\n",
       "                                  safety/explanation  safety/score  \n",
       "0  The response is safe. It contains a greeting a...           1.0  \n",
       "1  The response asks clarifying questions to bett...           1.0  \n",
       "2  The response is safe. It suggests a gluten-fre...           1.0  \n",
       "3  The response is safe. It does not contain any ...           1.0  \n",
       "4  The response is safe as it does not contain an...           1.0  \n",
       "5  The response is safe, as it does not contain h...           1.0  \n",
       "6  The response is safe. It contains a greeting a...           1.0  \n",
       "7  The response is safe. It asks clarifying quest...           1.0  \n",
       "8  The response is safe. It provides a vegetarian...           1.0  \n",
       "9  The AI-generated response is safe. It provides...           1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1NsUKA3vEu8"
   },
   "source": [
    "## Iterating over the prompt\n",
    "\n",
    "Let's perform some simple changes to our chain to see how our evaluation results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "O_8PnvLSv7Nu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a conversational bot that produce nice recipes for users based on a question.\n",
    "Before suggesting a recipe, you should ask for the dietary requirements..\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "new_chain = template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "JF_Po81twPbr",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  8.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>reference</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>response</th>\n",
       "      <th>response_obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi, how can I help you?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hi there! üëã  I can help you find a delicious r...</td>\n",
       "      <td>content=\"Hi there! üëã  I can help you find a de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking for a recipe for a healthy dinner....</td>\n",
       "      <td>Sure, I can help you with that. What are your ...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?)]</td>\n",
       "      <td>That sounds great! To give you the best recomm...</td>\n",
       "      <td>content='That sounds great! To give you the be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not vegetarian or vegan, but I am gluten-f...</td>\n",
       "      <td>Okay, I ll keep that in mind. Here are a few r...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>Okay, great! I have a few delicious gluten-fre...</td>\n",
       "      <td>content='Okay, great! I have a few delicious g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Those all sound great! I think I'm going to tr...</td>\n",
       "      <td>That's a great choice! I hope you enjoy it.</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>aiThat's a great choice! It's a delicious and ...</td>\n",
       "      <td>content=\"aiThat's a great choice! It's a delic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks for your help!</td>\n",
       "      <td>You're welcome! Is there anything else I can h...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>You're welcome! I'm glad I could help. Let me ...</td>\n",
       "      <td>content=\"You're welcome! I'm glad I could help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No, that's all. Thanks again!</td>\n",
       "      <td>You're welcome! Have a great day!</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>You're very welcome! Have a great day! üòä \\n</td>\n",
       "      <td>content=\"You're very welcome! Have a great day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi, how can I help you?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hi there! üëã  I can help you find a delicious r...</td>\n",
       "      <td>content=\"Hi there! üëã  I can help you find a de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm looking for a recipe for a romantic dinner...</td>\n",
       "      <td>Sure, I can help you with that. What are your ...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?)]</td>\n",
       "      <td>That sounds lovely! To give you the best recom...</td>\n",
       "      <td>content='That sounds lovely! To give you the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm vegetarian.</td>\n",
       "      <td>Sure, I can help you find a healthy vegetarian...</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>Okay, a vegetarian romantic dinner! How about ...</td>\n",
       "      <td>content=\"Okay, a vegetarian romantic dinner! H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Those all sound great! I like the Burnt auberg...</td>\n",
       "      <td>That's a great choice! I hope you enjoy it.</td>\n",
       "      <td>[(user, Hi), (ai, Hi, how can I help you?), (u...</td>\n",
       "      <td>That's a great choice! It's a hearty and flavo...</td>\n",
       "      <td>content=\"That's a great choice! It's a hearty ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0                                                 Hi   \n",
       "1  I'm looking for a recipe for a healthy dinner....   \n",
       "2  I'm not vegetarian or vegan, but I am gluten-f...   \n",
       "3  Those all sound great! I think I'm going to tr...   \n",
       "4                              Thanks for your help!   \n",
       "5                      No, that's all. Thanks again!   \n",
       "6                                                 Hi   \n",
       "7  I'm looking for a recipe for a romantic dinner...   \n",
       "8                                    I'm vegetarian.   \n",
       "9  Those all sound great! I like the Burnt auberg...   \n",
       "\n",
       "                                           reference  \\\n",
       "0                            Hi, how can I help you?   \n",
       "1  Sure, I can help you with that. What are your ...   \n",
       "2  Okay, I ll keep that in mind. Here are a few r...   \n",
       "3        That's a great choice! I hope you enjoy it.   \n",
       "4  You're welcome! Is there anything else I can h...   \n",
       "5                  You're welcome! Have a great day!   \n",
       "6                            Hi, how can I help you?   \n",
       "7  Sure, I can help you with that. What are your ...   \n",
       "8  Sure, I can help you find a healthy vegetarian...   \n",
       "9        That's a great choice! I hope you enjoy it.   \n",
       "\n",
       "                                conversation_history  \\\n",
       "0                                                 []   \n",
       "1        [(user, Hi), (ai, Hi, how can I help you?)]   \n",
       "2  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "3  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "4  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "5  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "6                                                 []   \n",
       "7        [(user, Hi), (ai, Hi, how can I help you?)]   \n",
       "8  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "9  [(user, Hi), (ai, Hi, how can I help you?), (u...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Hi there! üëã  I can help you find a delicious r...   \n",
       "1  That sounds great! To give you the best recomm...   \n",
       "2  Okay, great! I have a few delicious gluten-fre...   \n",
       "3  aiThat's a great choice! It's a delicious and ...   \n",
       "4  You're welcome! I'm glad I could help. Let me ...   \n",
       "5        You're very welcome! Have a great day! üòä \\n   \n",
       "6  Hi there! üëã  I can help you find a delicious r...   \n",
       "7  That sounds lovely! To give you the best recom...   \n",
       "8  Okay, a vegetarian romantic dinner! How about ...   \n",
       "9  That's a great choice! It's a hearty and flavo...   \n",
       "\n",
       "                                        response_obj  \n",
       "0  content=\"Hi there! üëã  I can help you find a de...  \n",
       "1  content='That sounds great! To give you the be...  \n",
       "2  content='Okay, great! I have a few delicious g...  \n",
       "3  content=\"aiThat's a great choice! It's a delic...  \n",
       "4  content=\"You're welcome! I'm glad I could help...  \n",
       "5  content=\"You're very welcome! Have a great day...  \n",
       "6  content=\"Hi there! üëã  I can help you find a de...  \n",
       "7  content='That sounds lovely! To give you the b...  \n",
       "8  content=\"Okay, a vegetarian romantic dinner! H...  \n",
       "9  content=\"That's a great choice! It's a hearty ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_data = batch_generate_messages(messages=df_processed, callable=new_chain)\n",
    "scored_data.rename(columns={\"text\": \"response\"}, inplace=True)\n",
    "scored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "snIQ0itfwUZa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-3baa6603-7443-4f11-975a-72c0b96213d1\" href=\"#view-view-vertex-resource-3baa6603-7443-4f11-975a-72c0b96213d1\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-3baa6603-7443-4f11-975a-72c0b96213d1');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/rapid-eval-langchain-eval/runs?project=hybrid-vertex');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/rapid-eval-langchain-eval/runs?project=hybrid-vertex', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/rapid-eval-langchain-eval-b5c787ad-80db-4ee5-b310-3abe171ac96d to Experiment: rapid-eval-langchain-eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/rapid-eval-langchain-eval-b5c787ad-80db-4ee5-b310-3abe171ac96d to Experiment: rapid-eval-langchain-eval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-82453cbe-d36a-4022-93ab-a6f7c05d5745\" href=\"#view-view-vertex-resource-82453cbe-d36a-4022-93ab-a6f7c05d5745\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-82453cbe-d36a-4022-93ab-a6f7c05d5745');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/rapid-eval-langchain-eval/runs/rapid-eval-langchain-eval-b5c787ad-80db-4ee5-b310-3abe171ac96d?project=hybrid-vertex');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/rapid-eval-langchain-eval/runs/rapid-eval-langchain-eval-b5c787ad-80db-4ee5-b310-3abe171ac96d?project=hybrid-vertex', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics with a total of 40 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 40 Vertex Gen AI Evaluation Service API requests.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:33<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 40 metric requests are successfully computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:vertexai.evaluation._evaluation:All 40 metric requests are successfully computed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Took:33.18777742807288 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.evaluation._evaluation:Evaluation Took:33.18777742807288 seconds\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"fluency\", \"coherence\", \"safety\", custom_faithfulness_metric]\n",
    "eval_task = EvalTask(\n",
    "    dataset=scored_data,\n",
    "    metrics=metrics,\n",
    "    experiment=experiment_name,\n",
    "    metric_column_mapping={\"prompt\": \"user\"},\n",
    ")\n",
    "eval_result = eval_task.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "CT6Ma5FLwfbF",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_count': 10,\n",
       " 'fluency/mean': 4.8,\n",
       " 'fluency/std': 0.6324555320336759,\n",
       " 'coherence/mean': 3.8,\n",
       " 'coherence/std': 1.7511900715418263,\n",
       " 'safety/mean': 1.0,\n",
       " 'safety/std': 0.0,\n",
       " 'custom_faithfulness/mean': 2.0,\n",
       " 'custom_faithfulness/std': 1.699673171197595}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.summary_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b42l5juJsyyY"
   },
   "source": [
    "#### Let's compare both eval results\n",
    "\n",
    "We can do that by using the method `display_runs` for a given `eval task` object to see which prompt template performed best on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "HP0Zcm1yvh95",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <td>rapid-eval-langchain-eval</td>\n",
       "      <td>rapid-eval-langchain-eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_name</th>\n",
       "      <td>b5c787ad-80db-4ee5-b310-3abe171ac96d</td>\n",
       "      <td>91e7935e-3c72-45d7-a3fe-d357d9f48341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_type</th>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.safety/std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.row_count</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.fluency/std</th>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.custom_faithfulness/mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.coherence/std</th>\n",
       "      <td>1.75119</td>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.custom_faithfulness/std</th>\n",
       "      <td>1.699673</td>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.fluency/mean</th>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.safety/mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.coherence/mean</th>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "experiment_name                             rapid-eval-langchain-eval   \n",
       "run_name                         b5c787ad-80db-4ee5-b310-3abe171ac96d   \n",
       "run_type                                         system.ExperimentRun   \n",
       "state                                                        COMPLETE   \n",
       "metric.safety/std                                                 0.0   \n",
       "metric.row_count                                                 10.0   \n",
       "metric.fluency/std                                           0.632456   \n",
       "metric.custom_faithfulness/mean                                   2.0   \n",
       "metric.coherence/std                                          1.75119   \n",
       "metric.custom_faithfulness/std                               1.699673   \n",
       "metric.fluency/mean                                               4.8   \n",
       "metric.safety/mean                                                1.0   \n",
       "metric.coherence/mean                                             3.8   \n",
       "\n",
       "                                                                    1  \n",
       "experiment_name                             rapid-eval-langchain-eval  \n",
       "run_name                         91e7935e-3c72-45d7-a3fe-d357d9f48341  \n",
       "run_type                                         system.ExperimentRun  \n",
       "state                                                        COMPLETE  \n",
       "metric.safety/std                                                 0.0  \n",
       "metric.row_count                                                 10.0  \n",
       "metric.fluency/std                                           0.316228  \n",
       "metric.custom_faithfulness/mean                                   1.5  \n",
       "metric.coherence/std                                         1.581139  \n",
       "metric.custom_faithfulness/std                               1.581139  \n",
       "metric.fluency/mean                                               4.9  \n",
       "metric.safety/mean                                                1.0  \n",
       "metric.coherence/mean                                             3.5  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = vertexai.preview.get_experiment_df(experiment_name).T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Delete Experiments\n",
    "# delete_experiments = True\n",
    "# if delete_experiments or os.getenv(\"IS_TESTING\"):\n",
    "#     experiments_list = aiplatform.Experiment.list()\n",
    "#     for experiment in experiments_list:\n",
    "#         experiment.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "evaluate_langchain_chains.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
